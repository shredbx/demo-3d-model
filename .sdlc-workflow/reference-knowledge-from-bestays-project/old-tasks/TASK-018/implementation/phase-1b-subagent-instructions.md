# Phase 1B: Vector Search with pgvector - Subagent Instructions

**Task:** TASK-018
**Story:** US-027
**Phase:** Phase 1B - Vector Similarity Search
**Target Subagent:** dev-backend-fastapi
**Estimated Time:** ~1.5 hours

---

## Executive Summary

Implement TRUE semantic search using pgvector and OpenAI embeddings. Build on Phase 1A's filter extraction to enable searches like "romantic getaway" matching properties with "intimate villa" descriptions.

**Phase 1A delivered:**
- `FilterExtractionService` - LLM-based filter extraction âœ…
- `PropertySearchOrchestrator` - Modular search coordinator âœ…
- Tests with 88% coverage âœ…

**Phase 1B adds:**
- `PropertyEmbeddingService` - Generate OpenAI embeddings
- `VectorSearchService` - Semantic similarity search with pgvector
- Migration to enable vector columns
- Backfill script for existing properties
- Hybrid ranking (filters + semantic similarity)

---

## CRITICAL CONTEXT

### Current State Analysis

**Property Model (PropertyV2):**
- âœ… Already has `description_embedding_en: Mapped[str | None]` (TEXT column)
- âœ… Already has `description_embedding_th: Mapped[str | None]` (TEXT column)
- âš ï¸ Currently TEXT type, needs migration to Vector(1536)
- ðŸ“ Location: `apps/server/src/server/models/property_v2.py` lines 240, 246

**Dependencies:**
- âœ… `openai>=1.54.0` already in pyproject.toml (line 27)
- âœ… `pgvector>=0.3.6` already in pyproject.toml (line 37)
- âœ… `OPENAI_API_KEY` already in config.py (line 80)
- âœ… `OPENAI_EMBEDDING_MODEL` already in config.py (line 81)
- âœ… `OPENAI_EMBEDDING_DIMENSIONS` already in config.py (line 82)

**Migrations:**
- Latest: `20251108_2331-58bf42569cea_create_property_v2_schema.py` (created properties table)
- pgvector extension: Already enabled by `20251025_enable_pgvector_extension.py`

**What You Need to Build:**
1. Migration to convert TEXT columns to Vector(1536)
2. `PropertyEmbeddingService` class
3. `VectorSearchService` class
4. Update `PropertySearchOrchestrator` to use vector search
5. Backfill script for embeddings
6. Tests with â‰¥80% coverage
7. **MANDATORY:** External validation with curl (4 test cases)

---

## Phase 1B Requirements

### 1. Database Migration

**File:** `apps/server/alembic/versions/YYYYMMDD_HHMM_add_property_vector_search.py`

**Purpose:** Convert existing TEXT embedding columns to pgvector Vector type

**Migration Steps:**

```python
"""add property vector search support

Revision ID: <auto-generated>
Revises: 58bf42569cea
Create Date: <auto-generated>

Changes:
- Convert description_embedding_en from TEXT to vector(1536)
- Convert description_embedding_th from TEXT to vector(1536)
- Add ivfflat index for cosine similarity search (EN)
- Add ivfflat index for cosine similarity search (TH)
"""

def upgrade() -> None:
    # Note: pgvector extension already enabled by previous migration

    # Convert TEXT columns to vector(1536)
    op.execute("""
        ALTER TABLE properties_v2
        ALTER COLUMN description_embedding_en
        TYPE vector(1536)
        USING description_embedding_en::vector
    """)

    op.execute("""
        ALTER TABLE properties_v2
        ALTER COLUMN description_embedding_th
        TYPE vector(1536)
        USING description_embedding_th::vector
    """)

    # Create ivfflat indexes for fast cosine similarity search
    # Lists parameter: sqrt(num_rows) for optimal performance
    # With 5 properties: lists=2, with 10k properties: lists=100
    op.execute("""
        CREATE INDEX idx_properties_embedding_en_cosine
        ON properties_v2
        USING ivfflat (description_embedding_en vector_cosine_ops)
        WITH (lists = 10)
    """)

    op.execute("""
        CREATE INDEX idx_properties_embedding_th_cosine
        ON properties_v2
        USING ivfflat (description_embedding_th vector_cosine_ops)
        WITH (lists = 10)
    """)

def downgrade() -> None:
    # Drop indexes
    op.execute("DROP INDEX IF EXISTS idx_properties_embedding_en_cosine")
    op.execute("DROP INDEX IF EXISTS idx_properties_embedding_th_cosine")

    # Convert back to TEXT
    op.execute("""
        ALTER TABLE properties_v2
        ALTER COLUMN description_embedding_en
        TYPE text
    """)

    op.execute("""
        ALTER TABLE properties_v2
        ALTER COLUMN description_embedding_th
        TYPE text
    """)
```

**IMPORTANT NOTES:**
- Table name is `properties_v2` (NOT `properties`)
- Check actual table name in database: `\dt properties*` in psql
- Previous revision ID: Find latest migration in `alembic/versions/`
- pgvector extension already enabled, don't enable again
- Use `properties_v2` consistently (this was the mistake in TASK-013 planning)

**Validation:**
```bash
# Run migration
docker exec -i bestays-server-dev alembic upgrade head

# Verify in psql
docker exec -i bestays-db-dev psql -U postgres -d bestays -c "\d+ properties_v2"
# Should show: description_embedding_en | vector(1536)
```

---

### 2. Update Property Model

**File:** `apps/server/src/server/models/property_v2.py`

**Changes:**

```python
# Add import at top
from pgvector.sqlalchemy import Vector

# Update column definitions (around lines 240-250)
# OLD:
description_embedding_en: Mapped[str | None] = mapped_column(
    Text,
    nullable=True,
    comment="Description embedding (EN) - TODO: Vector(1536) when pgvector installed",
)

# NEW:
description_embedding_en: Mapped[str | None] = mapped_column(
    Vector(1536),
    nullable=True,
    comment="Description embedding (EN) for semantic search",
)

# Same change for description_embedding_th
description_embedding_th: Mapped[str | None] = mapped_column(
    Vector(1536),
    nullable=True,
    comment="Description embedding (TH) for semantic search",
)
```

**Note:** Remove TODO comments since pgvector is now installed

---

### 3. Embedding Service

**File:** `apps/server/src/server/services/search/embedding_service.py`

**Architecture Header:**
```python
"""
Property Embedding Service - OpenAI Embeddings for Semantic Search

ARCHITECTURE:
  Layer: Service Layer
  Pattern: Service Pattern
  Task: TASK-018 (US-027) Phase 1B

PATTERNS USED:
  - Service Pattern: Encapsulates embedding generation logic
  - Dependency Injection: OpenAI client injected
  - Error Handling: Graceful degradation on API failures

DEPENDENCIES:
  External: openai, tiktoken
  Internal: server.config (settings)

INTEGRATION:
  - Used by: VectorSearchService, backfill script
  - OpenAI API: text-embedding-3-small model

TESTING:
  - Coverage Target: 85%
  - Test File: tests/services/search/test_embedding_service.py
"""
```

**Class Implementation:**

```python
from typing import Optional
from openai import AsyncOpenAI
from server.config import settings
import logging

logger = logging.getLogger(__name__)

class PropertyEmbeddingService:
    """
    Generate embeddings for properties using OpenAI.

    Uses text-embedding-3-small (1536 dimensions) for semantic search.
    Combines property text into single embedding.

    Example:
        service = PropertyEmbeddingService()

        # Generate from text
        embedding = await service.generate_embedding("Modern villa with pool")

        # Generate from property object
        property = await db.get(PropertyV2, property_id)
        embedding = await service.generate_property_embedding(property)
    """

    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = settings.OPENAI_EMBEDDING_MODEL  # "text-embedding-3-small"
        self.dimensions = settings.OPENAI_EMBEDDING_DIMENSIONS  # 1536

    async def generate_embedding(
        self,
        text: str,
        locale: str = "en"
    ) -> Optional[list[float]]:
        """
        Generate embedding vector for text.

        Args:
            text: Text to embed
            locale: Language locale (en, th) for context

        Returns:
            1536-dimensional vector or None on failure

        Example:
            >>> embedding = await service.generate_embedding("romantic villa")
            >>> len(embedding)
            1536
        """
        if not text or not text.strip():
            logger.warning("Empty text provided for embedding")
            return None

        try:
            # Call OpenAI API
            response = await self.client.embeddings.create(
                input=text.strip(),
                model=self.model,
                dimensions=self.dimensions,
            )

            # Extract embedding vector
            embedding = response.data[0].embedding

            logger.info(f"Generated embedding for text (length={len(text)}, locale={locale})")
            return embedding

        except Exception as e:
            logger.error(f"Failed to generate embedding: {e}")
            return None

    async def generate_property_embedding(
        self,
        property: PropertyV2,
        locale: str = "en"
    ) -> Optional[list[float]]:
        """
        Generate embedding for property description.

        Combines: title + description + amenities + tags
        into single text for embedding.

        Args:
            property: PropertyV2 instance
            locale: Language locale (en, th)

        Returns:
            1536-dimensional vector or None on failure

        Example:
            >>> property = await db.get(PropertyV2, property_id)
            >>> embedding = await service.generate_property_embedding(property)
        """
        # Build combined text
        text_parts = [
            property.title,
            property.description,
        ]

        # Add amenities if present
        if property.amenities:
            amenity_list = []
            for category, items in property.amenities.items():
                amenity_list.extend(items)
            if amenity_list:
                text_parts.append("Amenities: " + ", ".join(amenity_list))

        # Add tags if present
        if property.tags:
            text_parts.append("Tags: " + ", ".join(property.tags))

        # Combine into single text
        combined_text = "\n".join(text_parts)

        # Generate embedding
        return await self.generate_embedding(combined_text, locale)
```

---

### 4. Vector Search Service

**File:** `apps/server/src/server/services/search/vector_search_service.py`

**Architecture Header:**
```python
"""
Vector Search Service - Semantic Property Search with pgvector

ARCHITECTURE:
  Layer: Service Layer
  Pattern: Repository Pattern
  Task: TASK-018 (US-027) Phase 1B

PATTERNS USED:
  - Repository Pattern: Database queries for vector search
  - Dependency Injection: Database session injected
  - Graceful Degradation: Works without embeddings

DEPENDENCIES:
  External: sqlalchemy, pgvector
  Internal: embedding_service, property models

INTEGRATION:
  - Used by: PropertySearchOrchestrator
  - Database: Uses pgvector cosine similarity

TESTING:
  - Coverage Target: 85%
  - Test File: tests/services/search/test_vector_search_service.py
"""
```

**Class Implementation:**

```python
from typing import Optional
from sqlalchemy import select, func, text
from sqlalchemy.ext.asyncio import AsyncSession
from server.models.property_v2 import PropertyV2
from server.services.search.embedding_service import PropertyEmbeddingService
import logging

logger = logging.getLogger(__name__)

class VectorSearchService:
    """
    Semantic property search using vector similarity.

    Uses pgvector cosine similarity to find properties
    matching query semantics (not just keywords).

    Example:
        service = VectorSearchService(db_session)

        # Search by semantic similarity
        results = await service.search_by_similarity(
            query="romantic getaway for couples",
            locale="en",
            limit=20,
            threshold=0.7
        )

        for property, score in results:
            print(f"{property.title}: {score:.2f}")
    """

    def __init__(self, db: AsyncSession):
        self.db = db
        self.embedding_service = PropertyEmbeddingService()

    async def search_by_similarity(
        self,
        query: str,
        locale: str = "en",
        limit: int = 20,
        threshold: float = 0.7,
    ) -> list[tuple[PropertyV2, float]]:
        """
        Search properties by vector similarity.

        Args:
            query: Natural language search query
            locale: Language locale (en, th)
            limit: Maximum results to return
            threshold: Minimum similarity score (0.0-1.0)

        Returns:
            List of (property, similarity_score) tuples
            Sorted by similarity (highest first)

        Example:
            >>> results = await service.search_by_similarity(
            ...     query="villa with mountain view",
            ...     locale="en"
            ... )
            >>> for prop, score in results:
            ...     print(f"{prop.title}: {score}")
        """
        # Generate embedding for query
        query_embedding = await self.embedding_service.generate_embedding(
            query,
            locale
        )

        if not query_embedding:
            logger.warning("Failed to generate query embedding, returning empty results")
            return []

        # Choose embedding column based on locale
        embedding_column = (
            PropertyV2.description_embedding_en
            if locale == "en"
            else PropertyV2.description_embedding_th
        )

        # pgvector cosine similarity query
        # <=> is cosine distance operator (0 = identical, 2 = opposite)
        # 1 - distance = similarity score (1.0 = identical, 0.0 = orthogonal)

        query_stmt = select(
            PropertyV2,
            (1 - embedding_column.cosine_distance(query_embedding)).label("similarity")
        ).where(
            PropertyV2.is_active == True,
            embedding_column.isnot(None),  # Only properties with embeddings
        ).order_by(
            embedding_column.cosine_distance(query_embedding)  # Ascending (closest first)
        ).limit(limit)

        result = await self.db.execute(query_stmt)
        rows = result.all()

        # Filter by threshold and return as list of tuples
        results = [
            (row.PropertyV2, row.similarity)
            for row in rows
            if row.similarity >= threshold
        ]

        logger.info(
            f"Vector search: {len(results)} results (threshold={threshold}, locale={locale})"
        )

        return results
```

**IMPORTANT NOTES:**
- Use `PropertyV2.is_active` (NOT `is_published`) - check model for correct field name
- pgvector cosine distance: `<=>` operator returns 0-2 (lower = more similar)
- Similarity score: `1 - distance` converts to 0-1 (higher = more similar)
- Filter `embedding_column.isnot(None)` to skip properties without embeddings

---

### 5. Update Orchestrator

**File:** `apps/server/src/server/services/search/orchestrator.py`

**Changes:**

```python
# 1. Add import at top
from server.services.search.vector_search_service import VectorSearchService

# 2. Update __init__ method
def __init__(self, db: AsyncSession):
    self.db = db

    # Phase 1A: Initialize filter extraction
    self.filter_extractor = FilterExtractionService()

    # Phase 1B: Initialize vector search (NEW)
    self.vector_search = VectorSearchService(db)

    # Phase 2: Availability service (future)
    self.availability = None

# 3. Update search() method signature
async def search(
    self,
    query: str,
    components: list[str] = ["filter_extraction", "vector_search"],  # UPDATED default
    ranking: str = "hybrid",  # UPDATED default
    locale: str = "en",
    page: int = 1,
    per_page: int = 20,
) -> tuple[list[PropertyResponse], int, dict[str, Any]]:

# 4. Update Step 4 (replace placeholder code around line 167-174)
# Step 4: Vector search (Phase 1B)
vector_results = []
if "vector_search" in components and query.strip():
    vector_results = await self.vector_search.search_by_similarity(
        query=query,
        locale=locale,
        limit=per_page * 3,  # Get more candidates for hybrid ranking
        threshold=0.6,  # Lower threshold for more results
    )
    metadata["vector_search"] = {
        "results_count": len(vector_results),
        "top_score": vector_results[0][1] if vector_results else 0.0,
    }

# 5. Add hybrid ranking logic (after Step 4, before Step 5)
# Step 4.5: Hybrid ranking
if ranking == "hybrid" and vector_results:
    # Build property ID -> score map
    vector_scores = {prop.id: score for prop, score in vector_results}

    # Boost properties that match both filters AND semantics
    hybrid_properties = []
    for prop in properties:
        base_score = 1.0

        # Add vector similarity boost (0.0-1.0)
        if prop.id in vector_scores:
            base_score += vector_scores[prop.id]

        hybrid_properties.append((prop, base_score))

    # Sort by combined score
    hybrid_properties.sort(key=lambda x: x[1], reverse=True)
    properties = [prop for prop, score in hybrid_properties]

    metadata["ranking"] = {
        "strategy": "hybrid",
        "filter_count": total,
        "vector_count": len(vector_results),
        "hybrid_count": len(properties),
    }

elif ranking == "vector" and vector_results:
    # Use only vector search results
    properties = [prop for prop, score in vector_results]
    total = len(properties)

    metadata["ranking"] = {
        "strategy": "vector_only",
        "results_count": total,
    }
```

---

### 6. Update __init__.py

**File:** `apps/server/src/server/services/search/__init__.py`

**Add exports:**

```python
from server.services.search.filter_extraction_service import FilterExtractionService
from server.services.search.orchestrator import PropertySearchOrchestrator
from server.services.search.embedding_service import PropertyEmbeddingService  # NEW
from server.services.search.vector_search_service import VectorSearchService  # NEW

__all__ = [
    "FilterExtractionService",
    "PropertySearchOrchestrator",
    "PropertyEmbeddingService",  # NEW
    "VectorSearchService",  # NEW
]
```

---

### 7. Backfill Script

**File:** `apps/server/scripts/backfill_property_embeddings.py`

**Purpose:** Generate embeddings for all existing properties

```python
#!/usr/bin/env python3
"""
Backfill Property Embeddings Script

Generates OpenAI embeddings for all properties without embeddings.

Usage:
    docker exec -i bestays-server-dev python scripts/backfill_property_embeddings.py

Features:
- Progress tracking
- Error handling (skip failed properties)
- Dry-run mode
- Locale selection (en, th, both)
"""

import asyncio
import logging
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from server.core.database import async_session_maker
from server.models.property_v2 import PropertyV2
from server.services.search.embedding_service import PropertyEmbeddingService

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def backfill_embeddings(
    locale: str = "both",  # "en", "th", "both"
    dry_run: bool = False,
):
    """
    Generate embeddings for properties without them.

    Args:
        locale: Which embeddings to generate ("en", "th", "both")
        dry_run: If True, show what would be done without making changes
    """
    embedding_service = PropertyEmbeddingService()

    async with async_session_maker() as db:
        # Query properties without embeddings
        if locale == "en":
            query = select(PropertyV2).where(
                PropertyV2.is_active == True,
                PropertyV2.description_embedding_en.is_(None)
            )
        elif locale == "th":
            query = select(PropertyV2).where(
                PropertyV2.is_active == True,
                PropertyV2.description_embedding_th.is_(None)
            )
        else:  # both
            query = select(PropertyV2).where(
                PropertyV2.is_active == True,
                (PropertyV2.description_embedding_en.is_(None)) |
                (PropertyV2.description_embedding_th.is_(None))
            )

        result = await db.execute(query)
        properties = result.scalars().all()

        total = len(properties)
        logger.info(f"Found {total} properties needing embeddings (locale={locale})")

        if dry_run:
            logger.info("DRY RUN - No changes will be made")
            for i, prop in enumerate(properties, 1):
                logger.info(f"  [{i}/{total}] {prop.id} - {prop.title[:50]}")
            return

        # Process each property
        success_count = 0
        error_count = 0

        for i, prop in enumerate(properties, 1):
            logger.info(f"[{i}/{total}] Processing: {prop.title[:50]}")

            try:
                # Generate EN embedding
                if locale in ("en", "both") and not prop.description_embedding_en:
                    embedding_en = await embedding_service.generate_property_embedding(
                        prop, locale="en"
                    )
                    if embedding_en:
                        prop.description_embedding_en = embedding_en
                        logger.info(f"  âœ“ Generated EN embedding")

                # Generate TH embedding
                if locale in ("th", "both") and not prop.description_embedding_th:
                    embedding_th = await embedding_service.generate_property_embedding(
                        prop, locale="th"
                    )
                    if embedding_th:
                        prop.description_embedding_th = embedding_th
                        logger.info(f"  âœ“ Generated TH embedding")

                # Commit changes
                await db.commit()
                success_count += 1

            except Exception as e:
                logger.error(f"  âœ— Failed: {e}")
                await db.rollback()
                error_count += 1
                continue

        logger.info(f"\nBackfill complete:")
        logger.info(f"  Success: {success_count}/{total}")
        logger.info(f"  Errors: {error_count}/{total}")


if __name__ == "__main__":
    import sys

    # Parse arguments
    locale = sys.argv[1] if len(sys.argv) > 1 else "both"
    dry_run = "--dry-run" in sys.argv

    # Run backfill
    asyncio.run(backfill_embeddings(locale=locale, dry_run=dry_run))
```

**Usage:**
```bash
# Dry run (preview)
docker exec -i bestays-server-dev python scripts/backfill_property_embeddings.py --dry-run

# Generate EN embeddings only
docker exec -i bestays-server-dev python scripts/backfill_property_embeddings.py en

# Generate both EN and TH embeddings
docker exec -i bestays-server-dev python scripts/backfill_property_embeddings.py both
```

---

### 8. Update Search Endpoint (Optional)

**File:** `apps/server/src/server/api/v1/endpoints/search.py`

**Optional Enhancement:** Add query parameters for component control

```python
# Update SemanticSearchRequest schema
class SemanticSearchRequest(BaseModel):
    query: str = Field(..., description="Natural language search query")
    locale: str = Field("en", description="Language locale (en, th)")
    page: int = Field(1, ge=1, description="Page number")
    per_page: int = Field(20, ge=1, le=100, description="Items per page")

    # NEW: Component and ranking control
    components: list[str] = Field(
        ["filter_extraction", "vector_search"],
        description="Search components to enable"
    )
    ranking: str = Field(
        "hybrid",
        description="Ranking strategy (basic, hybrid, vector)"
    )
```

This allows clients to control search behavior:
- `components=["filter_extraction"]` - Phase 1A behavior only
- `components=["vector_search"]` - Semantic search only
- `components=["filter_extraction", "vector_search"]` - Full hybrid search
- `ranking="hybrid"` - Combine filters + semantics
- `ranking="vector"` - Sort by semantic similarity only

---

### 9. Tests

**File:** `apps/server/tests/api/v1/test_search.py`

**Add these test cases:**

```python
# Phase 1B: Vector Search Tests

async def test_vector_search_semantic_similarity(client, db_session, sample_properties):
    """Test vector search finds semantically similar properties."""
    # Query: "romantic getaway"
    # Should match properties with "intimate", "cozy", "private" descriptions

    response = await client.post(
        "/api/v1/properties/search/semantic",
        json={
            "query": "romantic getaway for couples",
            "locale": "en",
            "components": ["vector_search"],
            "ranking": "vector"
        }
    )

    assert response.status_code == 200
    data = response.json()

    # Should return properties sorted by semantic similarity
    assert "properties" in data
    assert "metadata" in data
    assert data["metadata"]["components_used"] == ["vector_search"]
    assert "vector_search" in data["metadata"]


async def test_hybrid_ranking_combines_filters_and_vectors(client, db_session):
    """Test hybrid ranking boosts properties matching both filters and semantics."""
    response = await client.post(
        "/api/v1/properties/search/semantic",
        json={
            "query": "2 bedroom villa near beach",
            "locale": "en",
            "components": ["filter_extraction", "vector_search"],
            "ranking": "hybrid"
        }
    )

    assert response.status_code == 200
    data = response.json()

    # Should apply filters (2BR villa) AND semantic boost (beach descriptions)
    filters = data["metadata"]["extracted_filters"]
    assert filters.get("bedrooms") == 2
    assert filters.get("property_type") == "villa"

    # Should include hybrid ranking metadata
    assert data["metadata"]["ranking"]["strategy"] == "hybrid"


async def test_vector_search_disabled_fallback(client, db_session):
    """Test system works when vector_search component disabled."""
    response = await client.post(
        "/api/v1/properties/search/semantic",
        json={
            "query": "villa with pool",
            "locale": "en",
            "components": ["filter_extraction"],  # No vector_search
            "ranking": "basic"
        }
    )

    assert response.status_code == 200
    data = response.json()

    # Should work with Phase 1A behavior only
    assert data["metadata"]["components_used"] == ["filter_extraction"]
    assert data["metadata"]["ranking_strategy"] == "basic"


async def test_vector_search_empty_query_graceful(client, db_session):
    """Test vector search handles empty query gracefully."""
    response = await client.post(
        "/api/v1/properties/search/semantic",
        json={
            "query": "",
            "locale": "en",
            "components": ["vector_search"]
        }
    )

    assert response.status_code == 200
    data = response.json()

    # Should return all properties (no filtering)
    assert len(data["properties"]) > 0


async def test_backfill_script_generates_embeddings(db_session):
    """Test embedding generation for properties."""
    # Create property without embedding
    property = PropertyV2(
        title="Test Property",
        description="Modern villa with pool and garden",
        transaction_type="rent",
        property_type="villa",
        rent_price=3000000,
        currency="THB",
        physical_specs={},
        location_details={},
        amenities={},
        is_active=True,
        created_by=1
    )
    db_session.add(property)
    await db_session.commit()

    # Verify no embedding initially
    assert property.description_embedding_en is None

    # Run backfill (import and call function)
    from scripts.backfill_property_embeddings import backfill_embeddings
    await backfill_embeddings(locale="en", dry_run=False)

    # Refresh and verify embedding exists
    await db_session.refresh(property)
    assert property.description_embedding_en is not None
    assert len(property.description_embedding_en) == 1536
```

---

## Acceptance Criteria

### Functional Requirements
1. âœ… Migration converts TEXT columns to Vector(1536)
2. âœ… `PropertyEmbeddingService` generates embeddings via OpenAI
3. âœ… `VectorSearchService` finds similar properties by cosine distance
4. âœ… Orchestrator supports hybrid ranking (filters + vectors)
5. âœ… Backfill script generates embeddings for existing properties
6. âœ… Search endpoint accepts `components` and `ranking` parameters

### Non-Functional Requirements
1. âœ… Response time < 3 seconds (including embedding generation)
2. âœ… Test coverage â‰¥ 80%
3. âœ… Graceful degradation (works if embedding generation fails)
4. âœ… Migration is reversible (has `downgrade()` method)

### External Validation (MANDATORY)

**You MUST test with curl and document in your report:**

**Test 1: Vector Search Only**
```bash
curl -X POST http://localhost:8011/api/v1/properties/search/semantic \
  -H "Content-Type: application/json" \
  -d '{
    "query": "romantic getaway for couples",
    "locale": "en",
    "components": ["vector_search"],
    "ranking": "vector"
  }'
```
Expected: Returns properties sorted by semantic similarity

**Test 2: Hybrid Search (Filters + Vectors)**
```bash
curl -X POST http://localhost:8011/api/v1/properties/search/semantic \
  -H "Content-Type: application/json" \
  -d '{
    "query": "spacious villa near beach",
    "locale": "en",
    "components": ["filter_extraction", "vector_search"],
    "ranking": "hybrid"
  }'
```
Expected: Returns villas with beach descriptions, sorted by relevance

**Test 3: Backfill Script**
```bash
docker exec -i bestays-server-dev python scripts/backfill_property_embeddings.py both
```
Expected: All properties have embeddings generated

**Test 4: Performance**
```bash
time curl -X POST http://localhost:8011/api/v1/properties/search/semantic \
  -H "Content-Type: application/json" \
  -d '{"query": "family villa", "locale": "en"}' \
  -o /dev/null -s
```
Expected: < 3 seconds

---

## Report Requirements

Your implementation report MUST include:

1. **External Validation Section** (MANDATORY)
   - All 4 curl commands executed
   - Actual responses captured
   - Expected vs actual comparison
   - Performance metrics

2. **Files Created/Modified**
   - List all files with line counts
   - Brief description of each

3. **Test Results**
   - Coverage report
   - All tests passing
   - Any known issues documented

4. **Migration Verification**
   - Show `alembic upgrade head` output
   - Verify vector columns exist
   - Show indexes created

5. **Backfill Results**
   - Number of properties processed
   - Time taken
   - Any errors

6. **Deviations from Spec**
   - Document any changes to this specification
   - Justify why deviation was necessary

---

## Known Issues from Phase 1A

**Tags Filter Issue:**
- Phase 1A has known issue with tags filtering (PostgreSQL ARRAY overlap)
- Phase 1B does NOT need to fix this
- Focus on vector search implementation only
- Tags issue will be addressed separately

---

## Success Criteria

Phase 1B is complete when:
1. âœ… All files created and tests passing
2. âœ… Migration applied successfully
3. âœ… All properties have embeddings
4. âœ… External validation passed (4/4 tests)
5. âœ… Response time < 3s
6. âœ… Coverage â‰¥ 80%
7. âœ… Report includes external validation proof

---

## Estimated Time

~1.5 hours (based on Phase 1A actual time)

---

**BEGIN IMPLEMENTATION**

Remember:
- External validation with curl is MANDATORY
- Document all deviations from spec
- Maintain or exceed Phase 1A's 88% coverage
- Test graceful degradation (embedding failures)

**DO NOT:**
- Skip external validation
- Assume table names (verify in database)
- Skip migration testing
- Skip backfill script testing

**DELIVERABLE:** Implementation report following template above with PROOF of external validation.
